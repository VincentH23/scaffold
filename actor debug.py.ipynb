{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using backend: pytorch\n"
     ]
    }
   ],
   "source": [
    "from actor import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from MARS.common.nn import masked_softmax\n",
    "pred = torch.randn(size= (10,7))\n",
    "mask = torch.randint(0,2, size = (10,7))\n",
    "\n",
    "config = {\n",
    "    'device': 'cpu',\n",
    "    'n_atom_feat': 16,\n",
    "    'n_node_hidden': 64,\n",
    "    'n_bond_feat': 4,\n",
    "    'n_edge_hidden': 128,\n",
    "    'n_layers': 6,\n",
    "    'vocab_size': 10,\n",
    "    'batch_size': 128\n",
    "}\n",
    "actor = Actor(config)\n",
    "with open('mol_test.txt', 'r') as f:\n",
    "    mols = f.readlines()\n",
    "\n",
    "mols = [Chem.MolFromSmiles(smi.split(',')[0]) for smi in mols if Chem.MolFromSmiles(smi.split(',')[0])]\n",
    "\n",
    "graphs = [mol_to_dgl(mol) for mol in mols]\n",
    "graphs = dgl.batch(graphs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_act, p_del, p_add, p_arm, p_global=actor.get_prob(graphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([0.5066, 0.4934], grad_fn=<SqueezeBackward1>),\n",
       " tensor([0.5064, 0.4936], grad_fn=<SqueezeBackward1>),\n",
       " tensor([0.5066, 0.4934], grad_fn=<SqueezeBackward1>),\n",
       " tensor([0.5065, 0.4935], grad_fn=<SqueezeBackward1>),\n",
       " tensor([0.5066, 0.4934], grad_fn=<SqueezeBackward1>),\n",
       " tensor([0.5064, 0.4936], grad_fn=<SqueezeBackward1>),\n",
       " tensor([0.5064, 0.4936], grad_fn=<SqueezeBackward1>),\n",
       " tensor([0.5065, 0.4935], grad_fn=<SqueezeBackward1>),\n",
       " tensor([0.5065, 0.4935], grad_fn=<SqueezeBackward1>),\n",
       " tensor([0.5067, 0.4933], grad_fn=<SqueezeBackward1>),\n",
       " tensor([0.5066, 0.4934], grad_fn=<SqueezeBackward1>),\n",
       " tensor([0.5068, 0.4932], grad_fn=<SqueezeBackward1>),\n",
       " tensor([0.5065, 0.4935], grad_fn=<SqueezeBackward1>)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_act"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_idx =actor.conditional_idx2global_idx(1,10, 5, 3, p_del[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "121"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "global_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 0, 5, 3)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actor.global_idx2conditional_idx( global_idx, p_del[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conditional_to_global(add_idx,arm_idx,del_idx,p_act,p_add,p_arm,p_del,p_act_global):\n",
    "    p_add_cond = (p_act[1]*p_add[add_idx]*p_arm[add_idx,arm_idx]).item()\n",
    "    p_del_cond  = p_act[0]*p_del[del_idx].item()\n",
    "    \n",
    "    add_arm_glob_idx = actor.conditional_idx2global_idx(1,0,add_idx,arm_idx,p_del)\n",
    "    global_del_idx = actor.conditional_idx2global_idx(0,del_idx,0,0,p_del)\n",
    "    p_add_global =  p_act_global[add_arm_glob_idx].item()\n",
    "    p_del_global =  p_act_global[global_del_idx].item()\n",
    "    if p_add_cond != p_add_global :\n",
    "        print(p_add_cond-p_add_global)\n",
    "    assert abs(p_add_cond -p_add_global)<0.00001 \n",
    "    assert p_del_cond == p_del_global\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31, 68)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n  = dgl.unbatch(graphs)[0].number_of_nodes()\n",
    "e = dgl.unbatch(graphs)[0].number_of_edges()\n",
    "n,e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3283064365386963e-10\n",
      "2.3283064365386963e-10\n",
      "-2.3283064365386963e-10\n",
      "2.3283064365386963e-10\n",
      "2.3283064365386963e-10\n",
      "2.3283064365386963e-10\n",
      "-2.3283064365386963e-10\n",
      "-2.3283064365386963e-10\n",
      "-2.3283064365386963e-10\n",
      "-2.3283064365386963e-10\n",
      "-2.3283064365386963e-10\n",
      "-2.3283064365386963e-10\n",
      "-2.3283064365386963e-10\n",
      "-2.3283064365386963e-10\n",
      "2.3283064365386963e-10\n",
      "-2.3283064365386963e-10\n",
      "2.3283064365386963e-10\n",
      "-2.3283064365386963e-10\n",
      "2.3283064365386963e-10\n",
      "2.3283064365386963e-10\n",
      "-2.3283064365386963e-10\n",
      "2.3283064365386963e-10\n",
      "2.3283064365386963e-10\n",
      "2.3283064365386963e-10\n",
      "2.3283064365386963e-10\n",
      "2.3283064365386963e-10\n",
      "2.3283064365386963e-10\n",
      "2.3283064365386963e-10\n",
      "2.3283064365386963e-10\n",
      "-2.3283064365386963e-10\n",
      "-2.3283064365386963e-10\n",
      "-2.3283064365386963e-10\n",
      "-2.3283064365386963e-10\n",
      "2.3283064365386963e-10\n",
      "-2.3283064365386963e-10\n",
      "2.3283064365386963e-10\n",
      "2.3283064365386963e-10\n",
      "-2.3283064365386963e-10\n",
      "2.3283064365386963e-10\n",
      "-2.3283064365386963e-10\n",
      "-2.3283064365386963e-10\n",
      "-2.3283064365386963e-10\n",
      "-2.3283064365386963e-10\n",
      "2.3283064365386963e-10\n",
      "2.3283064365386963e-10\n",
      "-2.3283064365386963e-10\n",
      "-2.3283064365386963e-10\n",
      "2.3283064365386963e-10\n",
      "2.3283064365386963e-10\n",
      "2.3283064365386963e-10\n",
      "2.3283064365386963e-10\n",
      "-2.3283064365386963e-10\n",
      "-2.3283064365386963e-10\n",
      "-2.3283064365386963e-10\n",
      "-2.3283064365386963e-10\n",
      "-2.3283064365386963e-10\n",
      "-2.3283064365386963e-10\n",
      "-2.3283064365386963e-10\n",
      "2.3283064365386963e-10\n",
      "2.3283064365386963e-10\n",
      "2.3283064365386963e-10\n"
     ]
    }
   ],
   "source": [
    "###### add \n",
    "for add_idx in range(n):\n",
    "    for arm_idx in range(10):\n",
    "        conditional_to_global(add_idx,arm_idx,0,p_act[0],p_add[0],p_arm[0],p_del[0],p_global[0])\n",
    "        \n",
    "        \n",
    "###### del idx \n",
    "\n",
    "for del_idx in range(e):\n",
    "    conditional_to_global(0,0,del_idx,p_act[0],p_add[0],p_arm[0],p_del[0],p_global[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = dgl.unbatch(graphs)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "critic = Critic(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "actor_critic = ActorCritic(actor,critic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(215,\n",
       " -5.8836846351623535,\n",
       " {'act': 1, 'del': 0, 'add': 14, 'arm': 7, 'global_act': 215})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actor_critic.act(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 107 is out of bounds for dimension 0 with size 68",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mIndexError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-15-963e71e017df>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mlog\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mactor\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mget_prob\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mgraphs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m107\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;31mIndexError\u001B[0m: index 107 is out of bounds for dimension 0 with size 68"
     ]
    }
   ],
   "source": [
    "torch.log(actor.get_prob(graphs)[2][0][107])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-5.8837, grad_fn=<LogBackward>)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.log(actor.get_prob(graphs)[-1][0][215])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-5.8837, grad_fn=<LogBackward>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.log(actor.get_prob(graphs)[2][0][14]*actor.get_prob(graphs)[3][0][14,7]*actor.get_prob(graphs)[0][0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "action = torch.LongTensor([8,10,20,108,2,67,19,19,11,23,67,89,109])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ -4.0807, -15.9424, -15.9424, -15.9424,  -4.3162,  -5.8176,  -3.1657,\n",
       "         -15.9424, -15.9424,  -4.3689, -15.9424, -15.9424, -15.9424],\n",
       "        grad_fn=<SqueezeBackward1>),\n",
       " tensor([[-0.0515],\n",
       "         [-0.0523],\n",
       "         [-0.0517],\n",
       "         [-0.0522],\n",
       "         [-0.0513],\n",
       "         [-0.0523],\n",
       "         [-0.0519],\n",
       "         [-0.0567],\n",
       "         [-0.0519],\n",
       "         [-0.0514],\n",
       "         [-0.0514],\n",
       "         [-0.0508],\n",
       "         [-0.0515]], grad_fn=<AddmmBackward>),\n",
       " tensor([5.0028, 4.0781, 4.8137, 4.4974, 5.1479, 4.3920, 4.3884, 4.1299, 4.4223,\n",
       "         5.2208, 5.0952, 5.1183, 4.7029], grad_fn=<NegBackward>))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actor_critic.evaluate(graphs,action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-5.2208, grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(actor.get_prob(graphs)[-1][9]*torch.log(actor.get_prob(graphs)[-1][9]+1e-10)).sum()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "envMARS",
   "language": "python",
   "name": "envmars"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}